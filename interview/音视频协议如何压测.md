qd的音视频主要的负载主要在信令服务器这里，本身音视频是点对点的，评估不存在性能瓶颈。
信令服务主要的工作是什么？
会话session的维护，会话房间的创建，销毁。 会话发起的呼叫，心跳包的维护，接听，挂断等等。
所以整体的压测逻辑比较清楚，构造C（csv数据格式），C鉴权接入，每个C循环登录，创建房间，接入B，分析信令服务器的负载。

# 本身WebRTC协议是点对点的
WebRTC（Web Real-Time Communication）是一种实时音视频通信技术，提供了浏览器之间点对点（Peer-to-Peer，P2P）的音视频通信能力。因此，WebRTC 服务的核心部分是 P2P（点对点）的。然而，在实际应用中，你可能还需要一些辅助服务器组件来解决 NAT 穿越、信令和负载均衡等问题。

WebRTC 主要利用以下两种方式来建立和维护连接：

1. **点对点（P2P）**：
   
   WebRTC 使用 P2P 技术直接在浏览器端（客户端）间建立音视频连接。这种连接方式消除了中间服务器的需求并降低了延迟，从而实现高效、可扩展的实时音视频通信服务。

2. **辅助服务器组件**：

   尽管 WebRTC 提供了浏览器之间的 P2P 音视频连接功能，但在实际应用中，可能需要部署一些辅助服务器组件，例如：

   * **信令服务器**：WebRTC 本身并不规定信令协议。信令是在 WebRTC 建立连接前所必需的，它负责传递会话信息（如 SDP 描述符），以启动、维护和中止音视频连接。为了完成这些任务，你需要一个独立的信令服务器（如 WebSocket、XMPP 或 SIP 服务器）。

   * **NAT 穿越服务器**：在遇到复杂的网络环境和防火墙时，P2P 连接可能会受到限制。此时，需要使用 STUN、TURN 或 ICE 服务器来协助解决 NAT 穿越（NAT Traversal）问题。

   * **SFU（Selective Forwarding Unit）或 MCU（Multipoint Control Unit）**：以支持多人会议、有选择地转发或混合媒体流。

综上所述，WebRTC 服务的核心部分是基于 P2P 的点对点通信，但在实际使用场景中，辅助服务器组件也是必不可少的。这些组件可以解决实际应用中遇到的信令、NAT 穿越和负载均衡等问题，以确保 WebRTC 更流畅、可靠地进行音视频通信。

## SFU或MCU是什么？
SFU（Selective Forwarding Unit）和 MCU（Multipoint Control Unit）都是音视频会议系统中用于处理多点连接的服务器组件。它们的主要作用是管理多人会议中的音视频流，使得多个客户端之间可以实现音视频互动。

**SFU（Selective Forwarding Unit）**：  

SFU 是一种视频会议中的中间服务器，负责接收、处理和转发每个客户端的音视频流。它为每个参与方选择要转发的媒体流，而不会对音视频数据进行混合或解码。SFU 使每个客户端只需发送一份流，SFU 则将发送方的流处理并根据每个接收方的需求来转发合适的版本。

SFU 主要具有以下特点：

* 只转发而不解码、混合媒体流
* 每个参与方发送单个流，SFU 将其分发给其他参与方
* 对于需要不同质量的客户端，SFU 可以进行编码选项调整（称为 Simulcast）

**MCU（Multipoint Control Unit）**：

MCU 是一个音视频会议中用于混合多个客户端音视频流的服务器。它将收集来自所有客户端的音频流并将其混合成一个单独的音频流，同时将来自所有客户端的视频流合成一组或多组合成视频流。MCU 处理后的流将传输给会议所涉及的每个客户端。

MCU 主要具有以下特点：

* 对音视频流进行解码、混合和再编码
* 混合音频流、合成或拼接视频图像
* 系统资源消耗较高，因为需要对多个流进行编解码

SFU 和 MCU 的选择取决于所需功能及对性能和延迟的关注。当资源和计算能力有限时，SFU 可能更适合。MCU 的优势在于服务器提供混合音频和视频，以便于客户端处理。在实际场景中，根据所需的音视频处理方式、延迟要求和质量需求来选择 SFU、MCU 或两者的组合。


## 多人会议如何进行压测？
1、信令协议服务器的分析 --- 创建，加入，退出，关闭等等逻辑
2、音视频流的构建，管理多人会议中的音视频流服务器的压测。 数据构造（实时摄像头，本地视频文件载入等等）。