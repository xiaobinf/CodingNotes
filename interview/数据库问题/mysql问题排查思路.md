mysql的关键配置
分析工具 mysqlreport
分析决策树：
1. key_buffer_size 使用率写命中 
2. 每秒操作数【DMS和qc_hits数值越大越好】 slow【根据业务判断慢日志是否合理】
3. Scan【全表扫描数】 Full join【全链接】 根据业务判断查询条件是否合理
4. 查询缓存 Memory usage[状态值:配置值]-使用率;Block Fragmnt-百分比值:值越大表示碎片严重，建议值在10%-20%。若值过大，可以调整query_cache_min_res_unit来降低
5. connections Max used[状态值:配置值]%Max使用
率，若达到配置值，则需要增加
6. tmp_table_size可使用此值来增加临时表的内存大小 临时表创建在:磁盘(Disk table) 、内存 (Table) 以及临时文件 (Fii
)上，尽量减少时间表的创建，若要创建尽量创建在内存中
7. innodb buffer_pool size、innodb flush log at trx commit、sync binlog  Usage[状态值:配置值]-%Used: 使用率;
ead hit:缓存命中率，最好接近100%
8. max connections Max used[状态值:配置值]%Max使用
率，若达到配置值，则需要增加



一个bug场景：
压测的过程中出现TPS陡然掉坑的情况：
刚开始根据经验怀疑是压测的线程数过高，某些服务或者组件因为内存占用过高导致了重新，但是结合全链路的监控来看，服务负载都是正常的。我们试着降低TPS 300-200-50-1，TPS还是会出现掉坑。这非常像某个资源因为处理业务量的累积达到了某个临界点而产生的情形。
从全链路架构图来分析数据。
查应用服务器
从每个服务节点 top来查看，应用服务器没啥压力，在这样的状态中，你可能都不用再去查其他的操作系统信息了，因为目前的压力对这个系统来说确实是小了点。
查应用状态
应用的状态，这里用的工具仍然是前文中提到过多次的 JvisualVM，cpu占比小于15%，从堆曲线的趋势上来看，1G 的堆才到了 400M 多一点，并且回收一直都非常正常。怎么判断这个“正常”呢？首先，年轻代、年老代回收很有规律，并且没消耗什么 CPU；其次，每次 FullGC 都能回到 150M 左右，非常平稳。可见这个内存使用没啥问题。
网络：
当时也是查了网络的，只是也没什么压力
查DB:
DB 又是一个 MySQL，所以这里，我先手动执行了几个常规的查询语句。在 DB 中查看如下信息。查processlist、innodb_trx、innodb_locks、innodb_lock_waits。在没有监控工具时，这几个是我经常在 MySQL 数据库检查的表，因为数据库如果慢的话，基本上会在这几个表中留些蛛丝马迹。processlist 是看当前数据库中的 session 的，并且也会把正在执行的 SQL 列出来，快速刷新几次，就可以看到是不是有 SQL 一直卡在那里。
拿一条业务 SQL 执行一下，看看在压力之中会不会慢。这是在没有数据库监控时，快速判断业务的方法。因为这个业务很单一，用的 SQL 也单一，所以我在这里可以这样做。执行了之后，并没有发现业务 SQL 慢。

在没有其它监控工具的情况下，当时我们上了最傻最二最基础又最有效的时间拆分手段：抓包！抓包其实是个挺需要技巧的活，不止是说你能把包抓出来，还要能分析出来时间消耗在谁那里。
数据库的一个主机上看到了如下信息：TCP segment of a reassembled PDU 没有？它之上是 ACK。放大一下，看看这里的时间：2s

为什么 TCP 层要干这个事呢？上层应用给了你一大块数据包，你直接往外扔不就行了吗？还要自己 reassemble（重新装配），费老大劲。这其实 TCP 的一个参数来决定的，它就是 MSS（Maximum Segment Size）。在 TCP 一开始打招呼的时候（就是握手的过程），已经通过 MSS 这个可选项告诉对方自己能接收的最大报文是多少了，这是不加任何信息的大小，纯的。而在以太网上，这个值是设置为 1460 字节的，为啥是 1460 呢？因为加上 TCP 头的 20 个字节和 IP 头的 20 个字节，刚好不大不小 1500 字节。当你看到 1500 字节的时候，是不是有一种似曾相识的感觉？它就是现在普遍设置的 MTU（Maximum Transmission Unit）的大小呀。

数据库**主机**自己耗时了两秒来做 reassemble PDU。至于吗？不就是过来查个数据吗？考虑了一下业务特征，这就是根据客户 ID 查一个帐户的一个月或三个月的记录信息，通常是 100 条左右，最多也就 200 条，也不至于有这么大。但是不管怎么样，还是数据库的问题！这就是我前面说的查 DB 的时候，由于证据不全导致了分析思路的偏差。因为我手动执行了这个语句的时候并不慢，只要 10 几毫秒，所以，那时候我觉得数据库不是问题点。

接着看 DB 上的信息了，既然数据量大，SQL 执行得慢，那就先捞出慢日志看看。

DB proxy 层的所有 SQL 日志拿出来分析一遍。为什么我要 DB proxy 层的数据呢？因为这一段会把所有执行的 SQL 都记录下来，而慢日志记录的是 1s 以上的（取决于 DB 中的配置）。首先是把 time cost 大于 200ms 的 SQL 都拉出来，结果发现，真的在 TPS 下降的那个时间段，出现了 SQL 执行超长的情况，并且和我执行的，还是同样的业务 SQL。

问题基本上就明确了，查一下参数化的数据，里面有 10 万条数据，而取到记录数在五六万左右的客户 ID 的时候，才出现了响应时间长的问题。而我之前的执行的 SQL，恰好试了多次都是数据量少的。
一开始数据库里的基础数据不够。由于我在项目中要求基础数据量和参数化数据量要达到生产级别。于是把这个工作安排给了一个同事，就是造出每个客户都和生产环境中差不多量级的记录。当时是用压力脚本做客户 ID 的参数化

核心经验：
数据分布和生产不一致，压出来性能结果很难预估生产真实性能的情形



reassemble PDU指的是将被分割成多个小数据包的数据重新组合成原始数据的过程。在计算机网络中，为了在网络上传输大量数据，数据通常会被分割成多个小数据包，然后单独传输。这些小数据包在传输过程中可能会经过不同的路径，因此可能会以不同的顺序到达接收端。在接收端，这些小数据包需要被重新组合成原始数据，这个过程就叫做reassemble PDU。Protocol Data Unit。

通常，reassemble PDU是由传输控制协议（TCP）来完成的。TCP将数据分割成多个小数据包（也称为TCP分段），并在每个数据包中添加序列号和确认号等控制信息。接收端收到这些小数据包后，会根据序列号将它们重新组合成原始数据。如果有任何数据包丢失或损坏，TCP会自动重新传输这些数据包，以确保数据的完整性和可靠性。




高IO等待排查思路
top 面临 查看cpu的wa参数值
wa值过高 结合CPU热点与通过iotop查看io栈 看下是在哪里有问题